info:
  contact:
    email: contact@bentoml.ai
  description: A Prediction Service built with BentoML
  title: lgbm_classifier
  version: 0.0.0
openapi: 3.0.0
paths:
  /healthz:
    get:
      description: Health check endpoint. Expecting an empty response with status
        code <code>200</code> when the service is in health state. The <code>/healthz</code>
        endpoint is <b>deprecated</b> (since Kubernetes v1.16)
      responses: &id001
        '200':
          description: success
      tags:
      - infra
  /livez:
    get:
      description: Health check endpoint for Kubernetes. Healthy endpoint responses
        with a <code>200</code> OK status.
      responses: *id001
      tags:
      - infra
  /metrics:
    get:
      description: Prometheus metrics endpoint
      responses: *id001
      tags:
      - infra
  /predict:
    post:
      description: ''
      operationId: lgbm_classifier__predict
      requestBody:
        content:
          application/json:
            schema:
              type: object
      responses:
        '200':
          content:
            text/plain:
              schema:
                type: string
          description: success
        '400':
          description: Bad Request
        '404':
          description: Not Found
        '500':
          description: Internal Server Error
      summary: "InferenceAPI(PandasDataFrame() \u2192 Text())"
      tags:
      - app
  /readyz:
    get:
      description: A <code>200</code> OK status from <code>/readyz</code> endpoint
        indicated the service is ready to accept traffic. From that point and onward,
        Kubernetes will use <code>/livez</code> endpoint to perform periodic health
        checks.
      responses: *id001
      tags:
      - infra
tags:
- description: Infrastructure endpoints
  name: infra
- description: Inference endpoints
  name: app
