# -*- coding: utf-8 -*-
"""notebook.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/wandb/examples/blob/master/examples/wandb-sweeps/sweeps-python/notebook.ipynb
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install -q wandb

!wandb login

# %load train_lib.py

def train():
    import numpy as np
    import tensorflow as tf
    import wandb
    config_defaults = {
        'layer1_size': 128,
        'dropout_rate':0.2,
        'layer1_activation': 'relu',
        'optimizer':'adam',
        'learning_rate': 0.01
    }

    wandb.init(project='sweep-practice',
               config=config_defaults,
               magic=True)
    config = wandb.config

    fashion_mnist = tf.keras.datasets.fashion_mnist
    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

    train_images.shape
    train_images = train_images / 255.0
    test_images = test_images / 255.0

    model = tf.keras.Sequential([
        tf.keras.layers.Flatten(input_shape=(28, 28)),
        tf.keras.layers.Dense(config.layer1_size, activation=config.layer1_activation),
        tf.keras.layers.Dropout(config.dropout_rate),
        tf.keras.layers.Dense(10, activation=tf.nn.softmax)
    ])

    if config.optimizer == 'rmsprop':
      opt = tf.keras.optimizers.RMSprop(learning_rate=config.learning_rate)
    else:
      opt = tf.keras.optimizers.Adam(learning_rate=config.learning_rate)

    model.compile(optimizer=config.optimizer,
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    
    model.fit(train_images, train_labels, epochs=5,
                  validation_data=(test_images, test_labels))

sweep_config = {
    'method': 'grid',
    'parameters': {
        'layers1_size': {
            'values': [32, 64, 96, 128]
        },
        'layer1_activation': {
            'values': ['relu', 'sigmoid']
        },
        'dropout_rate':{
            'values': [0.1, 0.2, 0.3, 0.4, 0.5]
        },
        'optimizer':{
            'values': ['adam', 'rmsprop']
        },
        'learning_rate':{
            'values': [0.1, 0.01, 0.001]
        }
    }
}

import wandb
sweep_id = wandb.sweep(sweep_config, project='sweep-practice')

wandb.agent(sweep_id, function=train)

with open('train.py',"w") as f:
  f.write("""
import numpy as np
import tensorflow as tf
import wandb
config_defaults = {
    'layer1_size': 128,
    'dropout_rate':0.2,
    'layer1_activation': 'relu',
    'optimizer':'adam',
    'learning_rate': 0.01
}

wandb.init(project='sweep-practice',
            config=config_defaults,
            magic=True)
config = wandb.config

fashion_mnist = tf.keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
                'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

train_images.shape
train_images = train_images / 255.0
test_images = test_images / 255.0

model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(config.layer1_size, activation=config.layer1_activation),
    tf.keras.layers.Dropout(config.dropout_rate),
    tf.keras.layers.Dense(10, activation=tf.nn.softmax)
])

if config.optimizer == 'rmsprop':
  opt = tf.keras.optimizers.RMSprop(learning_rate=config.learning_rate)
else:
  opt = tf.keras.optimizers.Adam(learning_rate=config.learning_rate)

model.compile(optimizer=config.optimizer,
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(train_images, train_labels, epochs=5,
              validation_data=(test_images, test_labels))

   """)

!head train.py

!wandb agent minjun/sweep-practice/74vc0b9f

