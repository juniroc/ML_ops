# 12,13. 쿠베플로우 Part2

![12,13%20%E1%84%8F%E1%85%AE%E1%84%87%E1%85%A6%2085820/Untitled.png](12,13%20%E1%84%8F%E1%85%AE%E1%84%87%E1%85%A6%2085820/Untitled.png)

![12,13%20%E1%84%8F%E1%85%AE%E1%84%87%E1%85%A6%2085820/Untitled%201.png](12,13%20%E1%84%8F%E1%85%AE%E1%84%87%E1%85%A6%2085820/Untitled%201.png)

![12,13%20%E1%84%8F%E1%85%AE%E1%84%87%E1%85%A6%2085820/Untitled%202.png](12,13%20%E1%84%8F%E1%85%AE%E1%84%87%E1%85%A6%2085820/Untitled%202.png)

![12,13%20%E1%84%8F%E1%85%AE%E1%84%87%E1%85%A6%2085820/Untitled%203.png](12,13%20%E1%84%8F%E1%85%AE%E1%84%87%E1%85%A6%2085820/Untitled%203.png)

ex) 

함수를 데코레이터 이용해 컴포넌트만들고, 컴파일하면 Yaml 파일 생성 및 파이프라인 생성 

![12,13%20%E1%84%8F%E1%85%AE%E1%84%87%E1%85%A6%2085820/Untitled%204.png](12,13%20%E1%84%8F%E1%85%AE%E1%84%87%E1%85%A6%2085820/Untitled%204.png)

![12,13%20%E1%84%8F%E1%85%AE%E1%84%87%E1%85%A6%2085820/Untitled%205.png](12,13%20%E1%84%8F%E1%85%AE%E1%84%87%E1%85%A6%2085820/Untitled%205.png)

**→ 예측 가능한 값이 나오도록 컴포넌트를 구성하는 것이 좋음**

![12,13%20%E1%84%8F%E1%85%AE%E1%84%87%E1%85%A6%2085820/Untitled%206.png](12,13%20%E1%84%8F%E1%85%AE%E1%84%87%E1%85%A6%2085820/Untitled%206.png)

![12,13%20%E1%84%8F%E1%85%AE%E1%84%87%E1%85%A6%2085820/Untitled%207.png](12,13%20%E1%84%8F%E1%85%AE%E1%84%87%E1%85%A6%2085820/Untitled%207.png)

- 이런식으로 인풋과 아웃풋 지정을 해주어야 함
- 컴포넌트가 파이썬 함수일 필요는 없다 → 커멘트라인 인터페이스에서 argument나 output을 지정해 주면

![12,13%20%E1%84%8F%E1%85%AE%E1%84%87%E1%85%A6%2085820/Untitled%208.png](12,13%20%E1%84%8F%E1%85%AE%E1%84%87%E1%85%A6%2085820/Untitled%208.png)

![12,13%20%E1%84%8F%E1%85%AE%E1%84%87%E1%85%A6%2085820/Untitled%209.png](12,13%20%E1%84%8F%E1%85%AE%E1%84%87%E1%85%A6%2085820/Untitled%209.png)

![12,13%20%E1%84%8F%E1%85%AE%E1%84%87%E1%85%A6%2085820/Untitled%2010.png](12,13%20%E1%84%8F%E1%85%AE%E1%84%87%E1%85%A6%2085820/Untitled%2010.png)

### Data Passing

```python
import kfp
from kfp.components import func_to_container_op, InputPath, OutputPath

'''
InputPath, OutputPath를 잘봐야함.

OutputPath 는 패키징 될 때 자동으로 그 다음 컴포넌트에 전달이 되는 출력값이 됨

InputPath 는 명시한 Outputpath의 data file을 pass 시키라는 뜻
'''

EXPERIMENT_NAME = 'Data Passing'
KUBEFLOW_HOST = 'http://127.0.0.1:8080/pipeline'

# Writing bigger data
@func_to_container_op
def repeat_line(line: str, output_text_path: OutputPath(str), count: int = 10):
    '''Repeat the line specified number of times'''
    with open(output_text_path, 'w') as writer:
        for i in range(count):
            writer.write(line + '\n')

'''
위 repeat_line 컴포넌트에서 -> 아래의 print_text 컴포넌트로 
text_path로 파일을 전달할때
minio를 이용해서 전달 
'''

# Reading bigger data
@func_to_container_op
def print_text(text_path: InputPath()): # The "text" input is untyped so that any data can be printed
    '''Print text'''
    with open(text_path, 'r') as reader:
        for line in reader:
            print(line, end = '')

def print_repeating_lines_pipeline():
    repeat_lines_task = repeat_line(line='Hello', count=5000)
    print_text(repeat_lines_task.output) # Don't forget .output !

@func_to_container_op
def split_text_lines(source_path: InputPath(str), odd_lines_path: OutputPath(str), even_lines_path: OutputPath(str)):
    with open(source_path, 'r') as reader:
        with open(odd_lines_path, 'w') as odd_writer:
            with open(even_lines_path, 'w') as even_writer:
                while True:
                    line = reader.readline()
                    if line == "":
                        break
                    odd_writer.write(line)
                    line = reader.readline()
                    if line == "":
                        break
                    even_writer.write(line)

def text_splitting_pipeline():
    text = '\n'.join(['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten'])
    split_text_task = split_text_lines(text)
    print_text(split_text_task.outputs['odd_lines'])
    print_text(split_text_task.outputs['even_lines'])

# Writing many numbers
@func_to_container_op
def write_numbers(numbers_path: OutputPath(str), start: int = 0, count: int = 10):
    with open(numbers_path, 'w') as writer:
        for i in range(start, count):
            writer.write(str(i) + '\n')

# Reading and summing many numbers
@func_to_container_op
def sum_numbers(numbers_path: InputPath(str)) -> int:
    sum = 0
    with open(numbers_path, 'r') as reader:
        for line in reader:
            sum = sum + int(line)
    return sum

# Pipeline to sum 100000 numbers
def sum_pipeline(count: int = 100000):
    numbers_task = write_numbers(count=count)
    print_text(numbers_task.output)

    sum_task = sum_numbers(numbers_task.outputs['numbers'])
    print_text(sum_task.output)

# Combining all pipelines together in a single pipeline
def file_passing_pipelines():
    print_repeating_lines_pipeline()
    text_splitting_pipeline()
    sum_pipeline()

if __name__ == '__main__':
    # Compiling the pipeline
    kfp.compiler.Compiler().compile(file_passing_pipelines, __file__ + '.yaml')
		kfp.Client(host=KUBEFLOW_HOST).create_run_from_pipeline_func(
			file_passing_pipelines,
			arguments={},
			experiment_name=EXPERIMENT_NAME)
```

![12,13%20%E1%84%8F%E1%85%AE%E1%84%87%E1%85%A6%2085820/Untitled%2011.png](12,13%20%E1%84%8F%E1%85%AE%E1%84%87%E1%85%A6%2085820/Untitled%2011.png)

```python
'''
InputPath, OutputPath를 잘봐야함.

OutputPath 는 패키징 될 때 자동으로 그 다음 컴포넌트에 전달이 되는 출력값이 됨

InputPath 는 명시한 Outputpath의 data file을 pass 시키라는 뜻
'''

위 사진에서 보면 **print_text는 계속 재사용**되고 있는데

이는 그 전 컴포넌트에서 **OutputPath()** **를 통해 다음 컴포넌트로 전달**해주는 방법을 이용했고,

print_text에서는 **그것을 받는 InputPath()** 를 이용하여

**컴포넌트간의 data를 주고 받는 흐름을 생성**할 수 있음
```

### Output a Directory

```python
port kfp
from kfp.components import create_component_from_func, load_component_from_text, InputPath, OutputPath

**### InputPath 와 OutputPath 를 눈여겨 볼 것.**

EXPERIMENT_NAME = 'Output a directory'        # Name of the experiment in the UI
KUBEFLOW_HOST = "http://127.0.0.1:8080/pipeline"

### OutputPath() 를 넣으면 컴포넌트가 출력파라미터로 인식
@create_component_from_func
def produce_dir_with_files_python_op(output_dir_path: OutputPath(), num_files: int = 10):
    import os
    os.makedirs(output_dir_path, exist_ok=True)
    for i in range(num_files):
        file_path = os.path.join(output_dir_path, str(i) + '.txt')
        with open(file_path, 'w') as f:
            f.write(str(i))

@create_component_from_func
def list_dir_files_python_op(input_dir_path: InputPath()):
    import os
    dir_items = os.listdir(input_dir_path)
    for dir_item in dir_items:
        print(dir_item)

# Outputting directories from general command-line based components:

# yaml 파일로 컴포넌트 로드
produce_dir_with_files_general_op = load_component_from_text('''
name: Produce directory
inputs:
- {name: num_files, type: Integer}
outputs:
- {name: output_dir}
implementation:
  container:
    image: alpine  ### 가벼운 도커이미지
    command:
    - sh      ### 쉘
    - -ecx
    - |
      num_files="$0"
      output_path="$1"
      mkdir -p "$output_path"
      for i in $(seq "$num_files"); do
        echo "$i" > "$output_path/${i}.txt"
      done
    - {inputValue: num_files}
    - {outputPath: output_dir}
''')

list_dir_files_general_op = load_component_from_text('''
name: List dir files
inputs:
- {name: input_dir}
implementation:
  container:
    image: alpine
    command:
    - ls
    - {inputPath: input_dir}
''')

# Test pipeline

def dir_pipeline():
    produce_dir_python_task = produce_dir_with_files_python_op(num_files=15)
    list_dir_files_python_op(input_dir=produce_dir_python_task.output)

    produce_dir_general_task = produce_dir_with_files_general_op(num_files=15)
    list_dir_files_general_op(input_dir=produce_dir_general_task.output)

if __name__ == '__main__':
    kfp.Client(host=KUBEFLOW_HOST).create_run_from_pipeline_func(
        dir_pipeline,
        arguments={},
        experiment_name=EXPERIMENT_NAME)
```

---

### Storing Data

```python

import kfp
import kfp.dsl as dsl

EXPERIMENT_NAME = 'Storing data'        # Name of the experiment in the UI
KUBEFLOW_HOST = "http://127.0.0.1:8080/pipeline"

### volumn mount
@dsl.pipeline(
    name="Volume Op DAG",
    description="The second example of the design doc."
)
def volume_op_dag():
    vop = dsl.VolumeOp(
        name="create_pvc",
        resource_name="my-pvc",
        size="10Gi",
        modes=dsl.VOLUME_MODE_RWM
    )

    step1 = dsl.ContainerOp(
        name="step1",
        image="library/bash:4.4.23",
        command=["sh", "-c"],
        arguments=["echo 1 | tee /mnt/file1"],
        pvolumes={"/mnt": vop.volume}
    )

    step2 = dsl.ContainerOp(
        name="step2",
        image="library/bash:4.4.23",
        command=["sh", "-c"],
        arguments=["echo 2 | tee /mnt2/file2"],
        pvolumes={"/mnt2": vop.volume}
    )

### after 는 1과 2가 끝난다음에 진행
    step3 = dsl.ContainerOp(
        name="step3",
        image="library/bash:4.4.23",
        command=["sh", "-c"],
        arguments=["cat /mnt/file1 /mnt/file2"],
        pvolumes={"/mnt": vop.volume.after(step1, step2)}
    )

if __name__ == "__main__":
    import kfp.compiler as compiler
    compiler.Compiler().compile(volume_op_dag, __file__ + ".tar.gz")
    kfp.Client(host=KUBEFLOW_HOST).create_run_from_pipeline_func(
        volume_op_dag,
        arguments={},
        experiment_name=EXPERIMENT_NAME)
```